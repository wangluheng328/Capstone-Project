{"version":3,"sources":["webpack://[name]/webpack/bootstrap","webpack://[name]/webpack/runtime/define property getters","webpack://[name]/webpack/runtime/hasOwnProperty shorthand","webpack://[name]/./esm/ext/lz-parsers/utils.js","webpack://[name]/./esm/ext/lz-parsers/bed.js","webpack://[name]/./esm/helpers/parse.js","webpack://[name]/./esm/ext/lz-parsers/gwas/sniffers.js","webpack://[name]/./esm/ext/lz-parsers/index.js","webpack://[name]/./esm/ext/lz-parsers/gwas/parsers.js","webpack://[name]/./esm/ext/lz-parsers/ld.js"],"names":["__webpack_require__","exports","definition","key","o","Object","defineProperty","enumerable","get","obj","prop","prototype","hasOwnProperty","call","Set","REGEX_PVAL","has","num","Number","isInteger","missingToNull","values","nulls","placeholder","map","v","normalizeChr","chromosome","replace","toUpperCase","parsePvalToLog","value","is_neg_log","val","Error","Infinity","base","exponent","match","Math","log10","_bedMissing","_hasNum","REGEX_MARKER","parseMarker","test","slice","normalizeMarker","variant","chrom","pos","ref","alt","normalized","levenshtein","a","b","distanceMatrix","Array","length","fill","i","j","indicator","min","findColumn","column_synonyms","header_names","threshold","best_score","best_match","header","score","s","install","LocusZoom","Adapters","TabixUrlSource","LDServer","UserTabixLD","config","limit_fields","super","state","assoc_data","_buildRequestOptions","arguments","ld_refvar","__find_ld_refvar","_skip_request","options","Promise","resolve","_performRequest","records","filter","item","add","use","makeBed12Parser","normalize","line","tokens","trim","split","chromStart","chromEnd","name","strand","thickStart","thickEnd","itemRgb","blockCount","blockSizes","blockStarts","marker_col","chrom_col","pos_col","ref_col","alt_col","pvalue_col","is_neg_log_pvalue","rsid_col","beta_col","stderr_beta_col","allele_freq_col","allele_count_col","n_samples_col","is_alt_effect","delimiter","fields","chr","freq","allele_count","n_samples","rsid","beta","stderr_beta","alt_allele_freq","startsWith","toLowerCase","log_pval","undefined","result","parseAlleleFrequency","ref_alt","position","ref_allele","alt_allele","log_pvalue","header_row","data_rows","offset","headers","pval_config","ps","validateP","col","data","is_log","cleaned_vals","row","p","e","every","isNaN","log_p_col","p_col","getPvalColumn","position_config","first_row","headers_marked","find","col_name","choices","is_required","getChromPosRefAltColumns","keys","forEach","beta_config","validate_numeric","nums","ret","getEffectSizeColumns","assign","chromosome1","position1","variant1","chromosome2","position2","variant2","correlation"],"mappings":";iCACA,IAAIA,EAAsB,CCA1B,EAAwB,CAACC,EAASC,KACjC,IAAI,IAAIC,KAAOD,EACXF,EAAoBI,EAAEF,EAAYC,KAASH,EAAoBI,EAAEH,EAASE,IAC5EE,OAAOC,eAAeL,EAASE,EAAK,CAAEI,YAAY,EAAMC,IAAKN,EAAWC,MCJ3E,EAAwB,CAACM,EAAKC,IAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,EAAKC,I,4BCOlF,MAAM,EAAiB,IAAII,IAAI,CAAC,GAAI,IAAK,KAAM,MAAO,MAAO,MAAO,OAAQ,MAAO,OAAQ,OAAQ,OAAQ,OAAQ,OAK7GC,EAAa,+BAUnB,SAASC,EAAIC,GACT,OAAOC,OAAOC,UAAUF,GAQ5B,SAASG,EAAcC,EAAQC,EAAQ,EAAgBC,EAAc,MAEjE,OAAOF,EAAOG,KAAKC,GAAOH,EAAMN,IAAIS,GAAKF,EAAcE,IAQ3D,SAASC,EAAaC,GAClB,OAAOA,EAAWC,QAAQ,QAAS,IAAIC,cAU3C,SAASC,EAAeC,EAAOC,GAAa,GAExC,GAAc,OAAVD,EACA,OAAOA,EAEX,MAAME,GAAOF,EACb,GAAIC,EACA,OAAOC,EAGX,GAAIA,EAAM,GAAKA,EAAM,EACjB,MAAM,IAAIC,MAAM,uCAIpB,GAAY,IAARD,EAAW,CAEX,GAAc,MAAVF,EAEA,OAAOI,IAKX,IAAK,CAAEC,EAAM,CAAEC,GAAYN,EAAMO,MAAMvB,GAQvC,OAPAqB,GAAQA,EAGJC,EADa,KAAbA,GACYA,EAED,EAEF,IAATD,EACOD,MAEFI,KAAKC,OAAOJ,KAASC,GAElC,OAAQE,KAAKC,MAAMP,GC/EvB,SAASQ,EAAYV,GAEjB,OAAIA,SAAmD,MAAVA,EAClC,KAEJA,EAMX,SAASW,EAAQX,GAGb,OADAA,EAAQU,EAAYV,KACJA,EAAQ,KCjB5B,MAAMY,EAAe,yEASrB,SAASC,EAAYb,EAAOc,GAAO,GAC/B,MAAMP,EAAQP,GAASA,EAAMO,MAAMK,GACnC,GAAIL,EACA,OAAOA,EAAMQ,MAAM,GAEvB,GAAKD,EAGD,OAAO,KAFP,MAAM,IAAIX,MAAM,0CAA0CH,qDAYlE,SAASgB,EAAgBC,GACrB,MAAMV,EAAQM,EAAYI,GAC1B,IAAKV,EACD,MAAM,IAAIJ,MAAM,kDAAkDc,KAEtE,MAAOC,EAAOC,EAAKC,EAAKC,GAAOd,EAC/B,IAAIe,EAAa,GAAGJ,KAASC,IAI7B,OAHIC,GAAOC,IACPC,GAAc,IAAIF,KAAOC,KAEtBC,ECfX,SAASC,EAAYC,EAAGC,GAGpB,MAAMC,EAAiBC,MAAMF,EAAEG,OAAS,GACnCC,KAAK,MACLpC,KAAI,IAAMkC,MAAMH,EAAEI,OAAS,GACvBC,KAAK,QAKd,IAAK,IAAIC,EAAI,EAAGA,GAAKN,EAAEI,OAAQE,GAAK,EAChCJ,EAAe,GAAGI,GAAKA,EAM3B,IAAK,IAAIC,EAAI,EAAGA,GAAKN,EAAEG,OAAQG,GAAK,EAChCL,EAAeK,GAAG,GAAKA,EAG3B,IAAK,IAAIA,EAAI,EAAGA,GAAKN,EAAEG,OAAQG,GAAK,EAChC,IAAK,IAAID,EAAI,EAAGA,GAAKN,EAAEI,OAAQE,GAAK,EAAG,CACnC,MAAME,EAAYR,EAAEM,EAAI,KAAOL,EAAEM,EAAI,GAAK,EAAI,EAC9CL,EAAeK,GAAGD,GAAKtB,KAAKyB,IACxBP,EAAeK,GAAGD,EAAI,GAAK,EAC3BJ,EAAeK,EAAI,GAAGD,GAAK,EAC3BJ,EAAeK,EAAI,GAAGD,EAAI,GAAKE,GAI3C,OAAON,EAAeD,EAAEG,QAAQJ,EAAEI,QAWtC,SAASM,EAAWC,EAAiBC,EAAcC,EAAY,GAE3D,IAAIC,EAAaD,EAAY,EACzBE,EAAa,KACjB,IAAK,IAAIT,EAAI,EAAGA,EAAIM,EAAaR,OAAQE,IAAK,CAC1C,MAAMU,EAASJ,EAAaN,GAC5B,GAAe,OAAXU,EAGA,SAEJ,MAAMC,EAAQjC,KAAKyB,OAAOE,EAAgB1C,KAAKiD,GAAMnB,EAAYiB,EAAQE,MACrED,EAAQH,IACRA,EAAaG,EACbF,EAAaT,GAGrB,OAAOS,EC3DX,SAASI,EAAQC,GACb,GAAIA,EAAUC,SAAS5D,IAAI,kBAAmB,CAE1C,MAAM6D,EAAiBF,EAAUC,SAASpE,IAAI,kBACxCsE,EAAWH,EAAUC,SAASpE,IAAI,YAUxC,MAAMuE,UAAoBF,EACtB,YAAYG,GACHA,EAAOC,eACRD,EAAOC,aAAe,CAAC,WAAY,YAAa,gBAEpDC,MAAMF,GAGV,qBAAqBG,EAAOC,GACxB,IAAKA,EACD,MAAM,IAAIlD,MAAM,8CAIpB,MAAME,EAAO8C,MAAMG,wBAAwBC,WAC3C,OAAKF,EAAWzB,QAMhBvB,EAAKmD,UAAYT,EAASnE,UAAU6E,iBAAiBL,EAAOC,GACrDhD,IANHA,EAAKqD,eAAgB,EACdrD,GAQf,gBAAgBsD,GAEZ,OAAIA,EAAQD,cACDE,QAAQC,QAAQ,IAEpBV,MAAMW,gBAAgBH,GAGjC,iBAAiBI,EAASJ,GAGtB,OAAOI,EAAQC,QAAQC,GAASA,EAAe,WAAMN,EAAQH,aAKrEZ,EAAUC,SAASqB,IAAI,cAAelB,IAIrB,oBAAdJ,WAGPA,UAAUuB,IAAIxB,GAIlB,MAEA,EAFY,CAAEA,UAASyB,gBHxDvB,UAAyB,UAACC,GAAY,GAAQ,IAI1C,OAAQC,IACJ,MAAMC,EAASD,EAAKE,OAAOC,MAAM,MAIjC,IACIvD,EACAwD,EACAC,EACAC,EACAnC,EACAoC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,GACAZ,EAEJ,KAAMrD,GAASwD,GAAcC,GACzB,MAAM,IAAIxE,MAAM,qDAKpB,GAFA0E,EAASnE,EAAYmE,GAEjBR,IAEAnD,EAAQvB,EAAauB,GACrBwD,GAAcA,EAAa,EAC3BC,GAAYA,EAGZlC,EAAQ9B,EAAQ8B,GAChBqC,EAAanE,EAAQmE,GACrBC,EAAWpE,EAAQoE,GAEnBC,EAAUtE,EAAYsE,GAGtBC,EAAatE,EAAQsE,GAErBC,EAAaxE,EAAYwE,GACzBA,EAAcA,EAAoBA,EAAWrF,QAAQ,KAAM,IAAI4E,MAAM,KAAKhF,KAAKO,IAAWA,IAA/D,KAE3BmF,EAAczE,EAAYyE,GAC1BA,EAAeA,EAAqBA,EAAYtF,QAAQ,KAAM,IAAI4E,MAAM,KAAKhF,KAAKO,IAAWA,EAAQ,IAAxE,KAEzBkF,GAAcC,GAAeF,IAAeC,EAAWtD,SAAWqD,GAAcE,EAAYvD,SAAWqD,IACvG,MAAM,IAAI9E,MAAM,6FAGxB,MAAO,CACHe,QACAwD,aACAC,WACAC,OACAnC,QACAoC,SACAC,aACAC,WACAC,UACAC,aACAC,aACAC,iBGZ0B,eC7DtC,UACI,WAEIC,EAAU,UACVC,EAAS,QACTC,EAAO,QACPC,EAAO,QACPC,EAAO,WACPC,EAAU,kBAEVC,GAAoB,EAAK,SACzBC,EAAQ,SACRC,EAAQ,gBACRC,EAAe,gBACfC,EAAe,iBACfC,EAAgB,cAChBC,EAAa,cACbC,GAAgB,EAAI,UACpBC,EAAY,OAIhB,GAAIjH,EAAImG,IAAenG,EAAIoG,IAAcpG,EAAIqG,GACzC,MAAM,IAAInF,MAAM,2CAEpB,KAAMlB,EAAImG,IAAgBnG,EAAIoG,IAAcpG,EAAIqG,IAC5C,MAAM,IAAInF,MAAM,qCAGpB,GAAIlB,EAAI8G,IAAqB9G,EAAI6G,GAC7B,MAAM,IAAI3F,MAAM,6DAEpB,GAAIlB,EAAI8G,KAAsB9G,EAAI+G,GAC9B,MAAM,IAAI7F,MAAM,8EAIpB,OAAQmE,IACJ,MAAM6B,EAAS7B,EAAKG,MAAMyB,GAC1B,IAAIE,EACAjF,EACAC,EACAC,EAGAgF,EAIAC,EACAC,EAPAC,EAAO,KAGPC,EAAO,KACPC,EAAc,KACdC,EAAkB,KAItB,GAAI1H,EAAImG,IACHgB,EAAKjF,EAAKC,EAAKC,GAAOR,EAAYsF,EAAOf,EAAa,IAAI,OACxD,KAAInG,EAAIoG,KAAcpG,EAAIqG,GAI7B,MAAM,IAAInF,MAAM,4DAHhBiG,EAAMD,EAAOd,EAAY,GACzBlE,EAAMgF,EAAOb,EAAU,GAM3B,GADAc,EAAMzG,EAAayG,GACfA,EAAIQ,WAAW,MACf,MAAM,IAAIzG,MAAM,wCAAwCiG,iBAGxDnH,EAAIsG,KACJnE,EAAM+E,EAAOZ,EAAU,IAGvBtG,EAAIuG,KACJnE,EAAM8E,EAAOX,EAAU,IAGvBvG,EAAI0G,KACJa,EAAOL,EAAOR,EAAW,IAGzB,MAAmBvE,KACnBA,EAAM,MAEN,MAAmBC,KACnBA,EAAM,MAGN,MAAmBmF,GACnBA,EAAO,KACAA,IACPA,EAAOA,EAAKK,cACPL,EAAKI,WAAW,QACjBJ,EAAO,KAAKA,MAIpB,MAAMM,EAAW/G,EAAeoG,EAAOV,EAAa,GAAIC,GACxDtE,EAAMA,GAAO,KACbC,EAAMA,GAAO,KAETpC,EAAI6G,KACJO,EAAOF,EAAOL,EAAkB,IAEhC7G,EAAI8G,KACJO,EAAeH,EAAOJ,EAAmB,GACzCQ,EAAYJ,EAAOH,EAAgB,IAGnC/G,EAAI2G,KACJa,EAAON,EAAOP,EAAW,GACzBa,EAAO,MAAmBA,GAAQ,MAASA,GAG3CxH,EAAI4G,KACJa,EAAcP,EAAON,EAAkB,GACvCa,EAAc,MAAmBA,GAAe,MAASA,IAGzDZ,GAAmBC,KACnBY,ELzDZ,UAA8B,KAAEN,EAAI,aAAEC,EAAY,UAAEC,EAAS,cAAEN,GAAgB,IAC3E,QAAac,IAATV,QAAuCU,IAAjBT,EACtB,MAAM,IAAInG,MAAM,6DAGpB,IAAI6G,EACJ,QAAaD,IAATV,IAAuB,EAAepH,IAAIqH,IAAiB,EAAerH,IAAIsH,IAE9E,OAAO,KAEX,QAAaQ,IAATV,QAAuCU,IAAjBT,EACtBU,GAAUV,GAAgBC,EAAY,MACnC,IAAI,EAAetH,IAAIoH,GAC1B,OAAO,KAEPW,GAAUX,EAId,GAAIW,EAAS,GAAKA,EAAS,EACvB,MAAM,IAAI7G,MAAM,gDAEpB,OAAK8F,EAGEe,EAFI,EAAIA,EKkCWC,CAAqB,CACnCZ,OACAC,eACAC,YACAN,mBAGR,MAAMiB,EAAW9F,GAAOC,EAAO,IAAID,KAAOC,IAAQ,GAClD,MAAO,CACHzB,WAAYwG,EACZe,UAAWhG,EACXiG,WAAYhG,EAAMA,EAAItB,cAAgB,KACtCuH,WAAYhG,EAAMA,EAAIvB,cAAgB,KACtCmB,QAAS,GAAGmF,KAAOjF,IAAM+F,IACzBV,OACAc,WAAYR,EACZL,OACAC,cACAC,qBD1E0C,UDmItD,SAAmBY,EAAYC,EAAWC,EAAS,GAQ/C,MAAMC,EAAUH,EAAW9H,KAAKwE,GAAUA,EAAOA,EAAK4C,cAAgB5C,IACtEyD,EAAQ,GAAG7H,QAAQ,QAAS,IAE5B,MAAM8H,EAxIV,SAAuBJ,EAAYC,GAK/B,IAAII,EACJ,MAAMC,EAAY,CAACC,EAAKC,EAAMC,KAC1B,MAAMC,EAAe,EAAeF,EAAKtI,KAAKyI,GAAQA,EAAIJ,MAC1D,IACIF,EAAKK,EAAaxI,KAAK0I,GAAMpI,EAAeoI,EAAGH,KACjD,MAAOI,GACL,OAAO,EAEX,OAAOR,EAAGS,OAAOnI,IAASf,OAAOmJ,MAAMpI,MAGrCqI,EAAYrG,EAdO,CAAC,iBAAkB,aAAc,WAAY,aAcvBqF,GACzCiB,EAAQtG,EAdQ,CAAC,SAAU,UAAW,UAAW,OAAQ,UAAW,IAAK,WAcvCqF,GAExC,OAAkB,OAAdgB,GAAsBV,EAAUU,EAAWf,GAAW,GAC/C,CACH/B,WAAY8C,EAAY,EACxB7C,mBAAmB,GAGvB8C,GAASX,EAAUW,EAAOhB,GAAW,GAC9B,CACH/B,WAAY+C,EAAQ,EACpB9C,mBAAmB,GAIpB,KAwGa+C,CAAcf,EAASF,GAC3C,IAAKG,EACD,OAAO,KAEXD,EAAQC,EAAYlC,WAAa,GAAK,KACtC,MAAMiD,EAvGV,SAAkCnB,EAAYC,GAG1C,MASMmB,EAAYnB,EAAU,GAC5B,IAAIpC,EAAalD,EAVK,CAAC,QAAS,SAAU,WAAY,YAAa,gBAUxBqF,GAC3C,GAAmB,OAAfnC,GAAuBvE,EAAY8H,EAAUvD,IAAa,GAE1D,OADAA,GAAc,EACP,CAAEA,cAKb,MAAMwD,EAAiBrB,EAAWxG,QAC5B8H,EAAO,CACT,CAAC,YAnBc,CAAC,QAAS,MAAO,eAmBN,GAC1B,CAAC,UAnBc,CAAC,WAAY,MAAO,QAAS,MAAO,KAAM,MAAO,KAAM,uBAmB9C,GACxB,CAAC,UAhBc,CAAC,KAAM,MAAO,YAAa,UAAW,YAgB7B,GACxB,CAAC,UAhBc,CAAC,KAAM,MAAO,YAAa,UAAW,YAgB7B,IAEtB5F,EAAS,GACf,IAAK,IAAInB,EAAI,EAAGA,EAAI+G,EAAKjH,OAAQE,IAAK,CAClC,MAAOgH,EAAUC,EAASC,GAAeH,EAAK/G,GACxCgG,EAAM5F,EAAW6G,EAASH,GAChC,GAAY,OAARd,GAAgBkB,EAChB,OAAO,KAEC,OAARlB,IACA7E,EAAO6F,GAAYhB,EAAM,EAEzBc,EAAed,GAAO,MAG9B,OAAO7E,EA8DiBgG,CAAyBvB,EAASF,GAC1D,IAAKkB,EACD,OAAO,KAGXpK,OAAO4K,KAAKR,GAAiBS,SAAS/K,IAClCsJ,EAAQgB,EAAgBtK,IAAQ,QAGpC,MAAMgL,EA7DV,SAA8BhH,EAAcoF,GAIxC,SAAS6B,EAAiBvB,EAAKC,GAC3B,MAAME,EAAe,EAAeF,EAAKtI,KAAKyI,GAAQA,EAAIJ,MAC1D,IAAIwB,EACJ,IACIA,EAAOrB,EAAajE,QAAQ9D,GAAgB,OAARA,IAAcT,KAAKS,IAASA,IAClE,MAAOkI,GACL,OAAO,EAEX,OAAOkB,EAAKjB,OAAOnI,IAASf,OAAOmJ,MAAMpI,KAG7C,MAAM0F,EAAW1D,EAdG,CAAC,OAAQ,cAAe,cAAe,UAclBE,EAAc,GACjDyD,EAAkB3D,EAdG,CAAC,cAAe,SAAU,SAAU,iBAAkB,KAAM,kBAchCE,EAAc,GAE/DmH,EAAM,GAOZ,OANiB,OAAb3D,GAAqByD,EAAiBzD,EAAU4B,KAChD+B,EAAI3D,SAAWA,EAAW,GAEN,OAApBC,GAA4BwD,EAAiBxD,EAAiB2B,KAC9D+B,EAAI1D,gBAAkBA,EAAkB,GAErC0D,EAoCaC,CAAqB9B,EAASF,GAElD,OAAIG,GAAee,EACRpK,OAAOmL,OAAO,GAAI9B,EAAae,EAAiBU,GAAe,IAEnE,MCjKsD,kBE/EjE,UAA2B,UAAC/E,GAAY,GAAQ,IAC5C,OAAQC,IAGJ,IAAKoF,EAAaC,EAAWC,EAAUC,EAAaC,EAAWC,EAAUC,GAAe1F,EAAKE,OAAOC,MAAM,MAW1G,OAVIJ,IACAqF,EAAc/J,EAAa+J,GAC3BG,EAAclK,EAAakK,GAC3BD,EAAW5I,EAAgB4I,GAC3BG,EAAW/I,EAAgB+I,GAC3BJ,GAAaA,EACbG,GAAaA,EACbE,GAAeA,GAGZ,CAACN,cAAaC,YAAWC,WAAUC,cAAaC,YAAWC,WAAUC,kB","file":"ext/lz-parsers.min.js","sourcesContent":["// The require scope\nvar __webpack_require__ = {};\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","/**\n * Constant values used by GWAS parser\n */\n\n/**\n * @private\n */\nconst MISSING_VALUES = new Set(['', '.', 'NA', 'N/A', 'n/a', 'nan', '-nan', 'NaN', '-NaN', 'null', 'NULL', 'None', null]);\n\n/**\n * @private\n */\nconst REGEX_PVAL = /([\\d.-]+)([\\sxeE]*)([0-9-]*)/;\n\n\n/**\n * Utility helper that checks for the presence of a numeric value (incl 0),\n *  eg \"has column specified\"\n * @private\n * @param num\n * @returns {boolean}\n */\nfunction has(num) {\n    return Number.isInteger(num);\n}\n\n/**\n * Convert all missing values to a standardized input form\n * Useful for columns like pvalue, where a missing value explicitly allowed\n * @private\n */\nfunction missingToNull(values, nulls = MISSING_VALUES, placeholder = null) {\n    // TODO Make this operate on a single value; cache for efficiency?\n    return values.map((v) => (nulls.has(v) ? placeholder : v));\n}\n\n/**\n * Normalize chromosome representations\n * @private\n * @param {String} chromosome\n */\nfunction normalizeChr(chromosome) {\n    return chromosome.replace(/^chr/g, '').toUpperCase();\n}\n\n/**\n * Parse (and validate) a given number, and return the -log10 pvalue.\n * @private\n * @param value\n * @param {boolean} is_neg_log\n * @returns {number|null} The -log10 pvalue\n */\nfunction parsePvalToLog(value, is_neg_log = false) {\n    // TODO: In future, generalize this for other values prone to underflow\n    if (value === null) {\n        return value;\n    }\n    const val = +value;\n    if (is_neg_log) { // Take as is\n        return val;\n    }\n    // Regular pvalue: validate and convert\n    if (val < 0 || val > 1) {\n        throw new Error('p value is not in the allowed range');\n    }\n    //  0-values are explicitly allowed and will convert to infinity by design, as they often\n    //    indicate underflow errors in the input data.\n    if (val === 0) {\n        // Determine whether underflow is due to the source data, or value conversion\n        if (value === '0') {\n            // The source data is bad, so insert an obvious placeholder value\n            return Infinity;\n        }\n        // h/t @welchr: aggressively turn the underflowing string value into -log10 via regex\n        // Only do this if absolutely necessary, because it is a performance hit\n\n        let [, base, , exponent] = value.match(REGEX_PVAL);\n        base = +base;\n\n        if (exponent !== '') {\n            exponent = +exponent;\n        } else {\n            exponent = 0;\n        }\n        if (base === 0) {\n            return Infinity;\n        }\n        return -(Math.log10(+base) + +exponent);\n    }\n    return -Math.log10(val);\n}\n\n/**\n * @private\n */\nfunction parseAlleleFrequency({ freq, allele_count, n_samples, is_alt_effect = true }) {\n    if (freq !== undefined && allele_count !== undefined) {\n        throw new Error('Frequency and allele count options are mutually exclusive');\n    }\n\n    let result;\n    if (freq === undefined && (MISSING_VALUES.has(allele_count) || MISSING_VALUES.has(n_samples))) {\n        // Allele count parsing\n        return null;\n    }\n    if (freq === undefined && allele_count !== undefined) {\n        result = +allele_count / +n_samples / 2;\n    } else if (MISSING_VALUES.has(freq)) { // Frequency-based parsing\n        return null;\n    } else {\n        result = +freq;\n    }\n\n    // No matter how the frequency is specified, this stuff is always done\n    if (result < 0 || result > 1) {\n        throw new Error('Allele frequency is not in the allowed range');\n    }\n    if (!is_alt_effect) { // Orient the frequency to the alt allele\n        return 1 - result;\n    }\n    return result;\n}\n\nexport {\n    MISSING_VALUES,\n    missingToNull as _missingToNull,\n    has,\n    normalizeChr,\n    // Exports for unit testing\n    parseAlleleFrequency,\n    parsePvalToLog,\n};\n","/**\n * Parse BED-family files, which have 3-12 columns\n *   https://genome.ucsc.edu/FAQ/FAQformat.html#format1\n */\n\nimport {normalizeChr} from './utils';\n\n/**\n * @private\n */\nfunction _bedMissing(value) {\n    // BED files specify . as the missing/ null value character\n    if (value === null || value === undefined || value === '.') {\n        return null;\n    }\n    return value;\n}\n\n/**\n * @private\n */\nfunction _hasNum(value) {\n    // Return a number, or null if value marked as missing\n    value = _bedMissing(value);\n    return value ? +value : null;\n}\n\n/**\n * Parse a BED file, according to the widely used UCSC (quasi-)specification\n *\n * NOTE: This original version is aimed at tabix region queries, and carries an implicit assumption that data is the\n *  only thing that will be parsed. It makes no attempt to identify or handle header rows / metadata fields.\n *\n * @function\n * @alias module:ext/lz-parsers~makeBed12Parser\n * @param {object} options\n * @param {Boolean} options.normalize Whether to normalize the output to the format expected by LocusZoom (eg type coercion\n *  for numbers, removing chr chromosome prefixes, and using 1-based and inclusive coordinates instead of 0-based disjoint intervals)\n * @return function A configured parser function that runs on one line of text from an input file\n */\nfunction makeBed12Parser({normalize = true} = {}) {\n    /*\n     * @param {String} line The line of text to be parsed\n     */\n    return (line) => {\n        const tokens = line.trim().split('\\t');\n        // The BED file format has 12 standardized columns. 3 are required and 9 are optional. At present, we will not\n        //  attempt to parse any remaining tokens, or nonstandard files that reuse columns with a different meaning.\n        //   https://en.wikipedia.org/wiki/BED_(file_format)\n        let [\n            chrom,\n            chromStart,\n            chromEnd,\n            name,\n            score,\n            strand,\n            thickStart,\n            thickEnd,\n            itemRgb,\n            blockCount,\n            blockSizes,\n            blockStarts,\n        ] = tokens;\n\n        if (!(chrom && chromStart && chromEnd)) {\n            throw new Error('Sample data must provide all required BED columns');\n        }\n\n        strand = _bedMissing(strand);\n\n        if (normalize) {\n            // Mandatory fields\n            chrom = normalizeChr(chrom);\n            chromStart = +chromStart + 1;  // BED is 0 based start, but LZ plots start at 1\n            chromEnd = +chromEnd; // 0-based positions, intervals exclude end position\n\n            // Optional fields, require checking for blanks\n            score = _hasNum(score);\n            thickStart = _hasNum(thickStart);\n            thickEnd = _hasNum(thickEnd);\n\n            itemRgb = _bedMissing(itemRgb);\n\n            // LocusZoom doesn't use these fields for rendering. Parsing below is theoretical/best-effort.\n            blockCount = _hasNum(blockCount);\n\n            blockSizes = _bedMissing(blockSizes);\n            blockSizes = !blockSizes ? null : blockSizes.replace(/,$/, '').split(',').map((value) => +value); // Comma separated list of sizes -> array of integers\n\n            blockStarts = _bedMissing(blockStarts);\n            blockStarts = !blockStarts ? null : blockStarts.replace(/,$/, '').split(',').map((value) => +value + 1); // Comma separated list of sizes -> array of integers (start positions)\n\n            if (blockSizes && blockStarts && blockCount && (blockSizes.length !== blockCount || blockStarts.length !== blockCount)) {\n                throw new Error('Block size and start information should provide the same number of items as in blockCount');\n            }\n        }\n        return {\n            chrom,\n            chromStart,\n            chromEnd,\n            name,\n            score,\n            strand,\n            thickStart,\n            thickEnd,\n            itemRgb,\n            blockCount,\n            blockSizes,\n            blockStarts,\n        };\n    };\n}\n\nexport { makeBed12Parser };\n","/**\n * Parse useful entities\n */\n\n/**\n * @private\n */\nconst REGEX_MARKER = /^(?:chr)?([a-zA-Z0-9]+?)[_:-](\\d+)[_:|-]?(\\w+)?[/_:|-]?([^_]+)?_?(.*)?/;\n\n/**\n * Parse a single marker, cleaning up values as necessary\n * @private\n * @param {String} value\n * @param {boolean} test If called in testing mode, do not throw an exception\n * @returns {Array} chr, pos, ref, alt (if match found; ref and alt optional)\n */\nfunction parseMarker(value, test = false) {\n    const match = value && value.match(REGEX_MARKER);\n    if (match) {\n        return match.slice(1);\n    }\n    if (!test) {\n        throw new Error(`Could not understand marker format for ${value}. Should be of format chr:pos or chr:pos_ref/alt`);\n    } else {\n        return null;\n    }\n}\n\n/**\n * Normalize a provided variant string into the EPACTS-style `chrom:pos_ref/alt` format expected by LocusZoom and the Michigan LD Server\n *   This allows harmonizing various input data to a consistent format\n * @private\n * @param {String} variant A string that specifies variant information in one of several common formats (like chr1:99_A/C, 1-99-A-C, 1:99:A:C, etc)\n */\nfunction normalizeMarker(variant) {\n    const match = parseMarker(variant);\n    if (!match) {\n        throw new Error(`Unable to normalize marker format for variant: ${variant}`);\n    }\n    const [chrom, pos, ref, alt] = match;\n    let normalized = `${chrom}:${pos}`;\n    if (ref && alt) {\n        normalized += `_${ref}/${alt}`;\n    }\n    return normalized;\n}\n\n\nexport {\n    parseMarker,\n    normalizeMarker,\n};\n","/**\n * Sniffers: auto detect file format and parsing options for GWAS files.\n */\n\nimport { parseMarker } from '../../../helpers/parse';\nimport { MISSING_VALUES, parsePvalToLog, _missingToNull } from '../utils';\n\n/**\n * @private\n */\nfunction isNumeric(val) {\n    // Check whether an unparsed string is a numeric value\"\n    if (MISSING_VALUES.has(val)) {\n        return true;\n    }\n    return !Number.isNaN(+val);\n}\n\nfunction isHeader(row, { comment_char = '#', delimiter = '\\t' } = {}) {\n    // This assumes two basic rules: the line is not a comment, and gwas data is more likely\n    // to be numeric than headers\n    return row.startsWith(comment_char) || row.split(delimiter).every((item) => !isNumeric(item));\n}\n\n/**\n * Compute the levenshtein distance between two strings. Useful for finding the single best column\n *  name that matches a given rule.\n *  @private\n */\nfunction levenshtein(a, b) { // https://github.com/trekhleb/javascript-algorithms\n    // Create empty edit distance matrix for all possible modifications of\n    // substrings of a to substrings of b.\n    const distanceMatrix = Array(b.length + 1)\n        .fill(null)\n        .map(() => Array(a.length + 1)\n            .fill(null));\n\n    // Fill the first row of the matrix.\n    // If this is first row then we're transforming empty string to a.\n    // In this case the number of transformations equals to size of a substring.\n    for (let i = 0; i <= a.length; i += 1) {\n        distanceMatrix[0][i] = i;\n    }\n\n    // Fill the first column of the matrix.\n    // If this is first column then we're transforming empty string to b.\n    // In this case the number of transformations equals to size of b substring.\n    for (let j = 0; j <= b.length; j += 1) {\n        distanceMatrix[j][0] = j;\n    }\n\n    for (let j = 1; j <= b.length; j += 1) {\n        for (let i = 1; i <= a.length; i += 1) {\n            const indicator = a[i - 1] === b[j - 1] ? 0 : 1;\n            distanceMatrix[j][i] = Math.min(\n                distanceMatrix[j][i - 1] + 1, // deletion\n                distanceMatrix[j - 1][i] + 1, // insertion\n                distanceMatrix[j - 1][i - 1] + indicator, // substitution\n            );\n        }\n    }\n    return distanceMatrix[b.length][a.length];\n}\n\n/**\n * Return the index of the first column name that meets acceptance criteria\n * @private\n * @param {String[]} column_synonyms\n * @param {String[]}header_names\n * @param {Number} threshold Tolerance for fuzzy matching (# edits)\n * @return {Number|null} Index of the best matching column, or null if no match possible\n */\nfunction findColumn(column_synonyms, header_names, threshold = 2) {\n    // Find the column name that best matches\n    let best_score = threshold + 1;\n    let best_match = null;\n    for (let i = 0; i < header_names.length; i++) {\n        const header = header_names[i];\n        if (header === null) {\n            // If header is empty, don't consider it for a match\n            // Nulling a header provides a way to exclude something from future searching\n            continue; // eslint-disable-line no-continue\n        }\n        const score = Math.min(...column_synonyms.map((s) => levenshtein(header, s)));\n        if (score < best_score) {\n            best_score = score;\n            best_match = i;\n        }\n    }\n    return best_match;\n}\n\n\n/**\n * Return parser configuration for pvalues\n *\n * Returns 1-based column indices, for compatibility with parsers\n * @private\n * @param header_row\n * @param data_rows\n * @returns {{}}\n */\nfunction getPvalColumn(header_row, data_rows) {\n    // TODO: Allow overrides\n    const LOGPVALUE_FIELDS = ['neg_log_pvalue', 'log_pvalue', 'log_pval', 'logpvalue'];\n    const PVALUE_FIELDS = ['pvalue', 'p.value', 'p-value', 'pval', 'p_score', 'p', 'p_value'];\n\n    let ps;\n    const validateP = (col, data, is_log) => { // Validate pvalues\n        const cleaned_vals = _missingToNull(data.map((row) => row[col]));\n        try {\n            ps = cleaned_vals.map((p) => parsePvalToLog(p, is_log));\n        } catch (e) {\n            return false;\n        }\n        return ps.every((val) => !Number.isNaN(val));\n    };\n\n    const log_p_col = findColumn(LOGPVALUE_FIELDS, header_row);\n    const p_col = findColumn(PVALUE_FIELDS, header_row);\n\n    if (log_p_col !== null && validateP(log_p_col, data_rows, true)) {\n        return {\n            pvalue_col: log_p_col + 1,\n            is_neg_log_pvalue: true,\n        };\n    }\n    if (p_col && validateP(p_col, data_rows, false)) {\n        return {\n            pvalue_col: p_col + 1,\n            is_neg_log_pvalue: false,\n        };\n    }\n    // Could not auto-determine an appropriate pvalue column\n    return null;\n}\n\n/**\n * @private\n */\nfunction getChromPosRefAltColumns(header_row, data_rows) {\n    // Returns 1-based column indices, for compatibility with parsers\n    // Get from either a marker, or 4 separate columns\n    const MARKER_FIELDS = ['snpid', 'marker', 'markerid', 'snpmarker', 'chr:position'];\n    const CHR_FIELDS = ['chrom', 'chr', 'chromosome'];\n    const POS_FIELDS = ['position', 'pos', 'begin', 'beg', 'bp', 'end', 'ps', 'base_pair_location'];\n\n    // TODO: How to handle orienting ref vs effect?\n    // Order matters: consider ambiguous field names for ref before alt\n    const REF_FIELDS = ['A1', 'ref', 'reference', 'allele0', 'allele1'];\n    const ALT_FIELDS = ['A2', 'alt', 'alternate', 'allele1', 'allele2'];\n\n    const first_row = data_rows[0];\n    let marker_col = findColumn(MARKER_FIELDS, header_row);\n    if (marker_col !== null && parseMarker(first_row[marker_col], true)) {\n        marker_col += 1;\n        return { marker_col };\n    }\n\n    // If single columns were incomplete, attempt to auto detect 4 separate columns. All 4 must\n    //  be found for this function to report a match.\n    const headers_marked = header_row.slice();\n    const find = [\n        ['chrom_col', CHR_FIELDS, true],\n        ['pos_col', POS_FIELDS, true],\n        ['ref_col', REF_FIELDS, false],\n        ['alt_col', ALT_FIELDS, false],\n    ];\n    const config = {};\n    for (let i = 0; i < find.length; i++) {\n        const [col_name, choices, is_required] = find[i];\n        const col = findColumn(choices, headers_marked);\n        if (col === null && is_required) {\n            return null;\n        }\n        if (col !== null) {\n            config[col_name] = col + 1;\n            // Once a column has been assigned, remove it from consideration\n            headers_marked[col] = null;\n        }\n    }\n    return config;\n}\n\n/**\n * Identify which columns contain effect size (beta) and stderr of the effect size\n * @private\n * @param {String[]} header_names\n * @param {Array[]} data_rows\n * @returns {{}}\n */\nfunction getEffectSizeColumns(header_names, data_rows) {\n    const BETA_FIELDS = ['beta', 'effect_size', 'alt_effsize', 'effect'];\n    const STDERR_BETA_FIELDS = ['stderr_beta', 'stderr', 'sebeta', 'effect_size_sd', 'se', 'standard_error'];\n\n    function validate_numeric(col, data) {\n        const cleaned_vals = _missingToNull(data.map((row) => row[col]));\n        let nums;\n        try {\n            nums = cleaned_vals.filter((val) => val !== null).map((val) => +val);\n        } catch (e) {\n            return false;\n        }\n        return nums.every((val) => !Number.isNaN(val));\n    }\n\n    const beta_col = findColumn(BETA_FIELDS, header_names, 0);\n    const stderr_beta_col = findColumn(STDERR_BETA_FIELDS, header_names, 0);\n\n    const ret = {};\n    if (beta_col !== null && validate_numeric(beta_col, data_rows)) {\n        ret.beta_col = beta_col + 1;\n    }\n    if (stderr_beta_col !== null && validate_numeric(stderr_beta_col, data_rows)) {\n        ret.stderr_beta_col = stderr_beta_col + 1;\n    }\n    return ret;\n}\n\n/**\n * Attempt to guess the correct parser settings given a set of header rows and a set of data rows\n * @private\n * @param {String[]} header_row\n * @param {String[][]} data_rows\n * @param {int} offset Used to convert between 0 and 1-based indexing.\n * @return {Object|null} Returns null if a complete configuration could not suggested.\n */\nfunction guessGWAS(header_row, data_rows, offset = 1) {\n    // 1. Find a specific set of info: marker OR chr/pos/ref/alt ; pvalue OR log_pvalue\n    // 2. Validate that we will be able to parse the required info: fields present and make sense\n    // 3. Based on the field names selected, attempt to infer meaning: verify whether log is used,\n    //  and check ref/alt vs effect/noneffect\n    // 4. Return a parser config object if all tests pass, OR null.\n\n    // Normalize case and remove leading comment marks from line for easier comparison\n    const headers = header_row.map((item) => (item ? item.toLowerCase() : item));\n    headers[0].replace('/^#+/', '');\n    // Lists of fields are drawn from Encore (AssocResultReader) and Pheweb (conf_utils.py)\n    const pval_config = getPvalColumn(headers, data_rows, offset);\n    if (!pval_config) {\n        return null;\n    }\n    headers[pval_config.pvalue_col - 1] = null; // Remove this column from consideration\n    const position_config = getChromPosRefAltColumns(headers, data_rows);\n    if (!position_config) {\n        return null;\n    }\n    // Remove the position config from consideration for future matches\n    Object.keys(position_config).forEach((key) => {\n        headers[position_config[key]] = null;\n    });\n\n    const beta_config = getEffectSizeColumns(headers, data_rows);\n\n    if (pval_config && position_config) {\n        return Object.assign({}, pval_config, position_config, beta_config || {});\n    }\n    return null;\n}\n\nexport {\n    // Public members\n    guessGWAS,\n    // Symbols exported for testing\n    isHeader as _isHeader,\n    getPvalColumn as _getPvalColumn,\n    findColumn as _findColumn,\n    levenshtein as _levenshtein,\n};\n","/**\n * Optional LocusZoom extension: must be included separately, and after LocusZoom has been loaded\n *\n * This plugin exports helper function, as well as a few optional extra helpers for rendering the plot. The GWAS parsers can be used without registering the plugin.\n *\n * To use in an environment without special JS build tooling, simply load the extension file as JS from a CDN (after any dependencies):\n * ```\n * <script src=\"https://cdn.jsdelivr.net/npm/locuszoom@INSERT_VERSION_HERE/dist/ext/lz-parsers.min.js\" type=\"application/javascript\"></script>\n * ```\n *\n * To use with ES6 modules, import the helper functions and use them with your layout:\n *\n * ```\n * import { install, makeGWASParser, makeBed12Parser, makePlinkLDParser } from 'locuszoom/esm/ext/lz-parsers';\n * LocusZoom.use(install);\n * ```\n *\n * ### Features provided\n * * {@link module:LocusZoom_Adapters~UserTabixLD} (if the {@link module:ext/lz-tabix-source} extension is loaded first)\n *\n * @module ext/lz-parsers\n */\n\nimport { makeBed12Parser } from './bed';\nimport { makeGWASParser } from './gwas/parsers';\nimport { guessGWAS } from './gwas/sniffers';\nimport { makePlinkLdParser } from './ld';\n\n\n// Most of this plugin consists of standalone functions. But we can add a few simple custom classes to the registry that help to use parsed output\nfunction install(LocusZoom) {\n    if (LocusZoom.Adapters.has('TabixUrlSource')) {\n        // Custom Tabix adapter depends on another extension being loaded first\n        const TabixUrlSource = LocusZoom.Adapters.get('TabixUrlSource');\n        const LDServer = LocusZoom.Adapters.get('LDServer');\n\n        /**\n         * Load user-provided LD from a tabix file, and filter the returned set of records based on a reference variant. (will attempt to choose a reference variant based on the most significant association variant, if no state.ldrefvar is specified)\n         * @public\n         * @alias module:LocusZoom_Adapters~UserTabixLD\n         * @extends module:LocusZoom_Adapters~TabixUrlSource\n         * @see {@link module:ext/lz-tabix-source} for required extension and installation instructions\n         * @see {@link module:ext/lz-parsers} for required extension and installation instructions\n         */\n        class UserTabixLD extends TabixUrlSource {\n            constructor(config) {\n                if (!config.limit_fields) {\n                    config.limit_fields = ['variant2', 'position2', 'correlation'];\n                }\n                super(config);\n            }\n\n            _buildRequestOptions(state, assoc_data) {\n                if (!assoc_data) {\n                    throw new Error('LD request must depend on association data');\n                }\n                // If no state refvar is provided, find the most significant variant in any provided assoc data.\n                //   Assumes that assoc satisfies the \"assoc\" fields contract, eg has fields variant and log_pvalue\n                const base = super._buildRequestOptions(...arguments);\n                if (!assoc_data.length) {\n                    base._skip_request = true;\n                    return base;\n                }\n\n                // NOTE: Reuses a method from another adapter to mix in functionality\n                base.ld_refvar = LDServer.prototype.__find_ld_refvar(state, assoc_data);\n                return base;\n            }\n\n            _performRequest(options) {\n                // Skip request if this one depends on other data, and we are in a region with no data\n                if (options._skip_request) {\n                    return Promise.resolve([]);\n                }\n                return super._performRequest(options);\n            }\n\n            _annotateRecords(records, options) {\n                // A single PLINK LD file could contain several reference variants (SNP_A) in the same region.\n                //   Only show LD relative to the user-selected refvar in this plot.\n                return records.filter((item) => item['variant1'] === options.ld_refvar);\n            }\n        }\n\n\n        LocusZoom.Adapters.add('UserTabixLD', UserTabixLD);\n    }\n}\n\nif (typeof LocusZoom !== 'undefined') {\n    // Auto-register the plugin when included as a script tag. ES6 module users must register via LocusZoom.use()\n    // eslint-disable-next-line no-undef\n    LocusZoom.use(install);\n}\n\n// Support UMD (single symbol export)\nconst all = { install, makeBed12Parser, makeGWASParser, guessGWAS, makePlinkLdParser };\n\nexport default all;\n\nexport { install, makeBed12Parser, makeGWASParser, guessGWAS, makePlinkLdParser };\n","import {parseMarker} from '../../../helpers/parse';\n\nimport {\n    MISSING_VALUES,\n    has,\n    parseAlleleFrequency,\n    parsePvalToLog, normalizeChr,\n} from '../utils';\n\n\n/**\n * Specify how to parse a GWAS file, given certain column information.\n * Outputs an object with fields in portal API format.\n *\n * All column options must be provided as 1-indexed column IDs (human-friendly argument values)\n * @function\n * @alias module:ext/lz-parsers~makeGWASParser\n * @param options\n * @param [options.marker_col] A single identifier that specifies all of chrom, pos, ref, and alt as a single string field. Eg 1:23_A/C\n * @param [options.chrom_col] Chromosome\n * @param [options.pos_col] Position\n * @param [options.ref_col] Reference allele (relative to human reference genome, eg GRCh37 or 38).\n * @param [options.alt_col] Alt allele. Some programs specify generic A1/A2 instead; it is the job of the user to identify which columns of this GWAS are ref and alt.\n * @param [options.rsid_col] rsID\n * @param options.pvalue_col p-value (or -log10p)\n * @param [options.beta_col]\n * @param [options.stderr_beta_col]\n * @param [options.allele_freq_col] Specify allele frequencies directly\n * @param [options.allele_count_col] Specify allele frequencies in terms of count and n_samples\n * @param [options.n_samples_col]\n * @param [options.is_alt_effect=true] Some programs specify beta and frequency information in terms of ref, others alt. Identify effect allele to orient values to the correct allele.\n * @param [options.is_neg_log_pvalue=false]\n * @param [options.delimiter='\\t'] Since this parser is usually used with tabix data, this is rarely changed (tabix does not accept other delimiters)\n * @return {function(string)} A parser function that can be called on each line of text with the provided options\n */\nfunction makeGWASParser(\n    {\n        // Required fields\n        marker_col, // Identify the variant: marker OR chrom/pos/ref/alt\n        chrom_col,\n        pos_col,\n        ref_col,\n        alt_col,\n        pvalue_col, // pvalue (or log_pvalue; see options below)\n        // Optional fields\n        is_neg_log_pvalue = false,\n        rsid_col,\n        beta_col,\n        stderr_beta_col,\n        allele_freq_col, // Frequency: given directly, OR in terms of counts\n        allele_count_col,\n        n_samples_col,\n        is_alt_effect = true, // whether effect allele is oriented towards alt. We don't support files like METAL, where ref/alt may switch places per line of the file\n        delimiter = '\\t',\n    },\n) {\n    // Column IDs should be 1-indexed (human friendly)\n    if (has(marker_col) && has(chrom_col) && has(pos_col)) {\n        throw new Error('Must specify either marker OR chr + pos');\n    }\n    if (!(has(marker_col) || (has(chrom_col) && has(pos_col)))) {\n        throw new Error('Must specify how to locate marker');\n    }\n\n    if (has(allele_count_col) && has(allele_freq_col)) {\n        throw new Error('Allele count and frequency options are mutually exclusive');\n    }\n    if (has(allele_count_col) && !has(n_samples_col)) {\n        throw new Error('To calculate allele frequency from counts, you must also provide n_samples');\n    }\n\n\n    return (line) => {\n        const fields = line.split(delimiter);\n        let chr;\n        let pos;\n        let ref;\n        let alt;\n        let rsid = null;\n\n        let freq;\n        let beta = null;\n        let stderr_beta = null;\n        let alt_allele_freq = null;\n        let allele_count;\n        let n_samples;\n\n        if (has(marker_col)) {\n            [chr, pos, ref, alt] = parseMarker(fields[marker_col - 1], false);\n        } else if (has(chrom_col) && has(pos_col)) {\n            chr = fields[chrom_col - 1];\n            pos = fields[pos_col - 1];\n        } else {\n            throw new Error('Must specify all fields required to identify the variant');\n        }\n\n        chr = normalizeChr(chr);\n        if (chr.startsWith('RS')) {\n            throw new Error(`Invalid chromosome specified: value \"${chr}\" is an rsID`);\n        }\n\n        if (has(ref_col)) {\n            ref = fields[ref_col - 1];\n        }\n\n        if (has(alt_col)) {\n            alt = fields[alt_col - 1];\n        }\n\n        if (has(rsid_col)) {\n            rsid = fields[rsid_col - 1];\n        }\n\n        if (MISSING_VALUES.has(ref)) {\n            ref = null;\n        }\n        if (MISSING_VALUES.has(alt)) {\n            alt = null;\n        }\n\n        if (MISSING_VALUES.has(rsid)) {\n            rsid = null;\n        } else if (rsid) {\n            rsid = rsid.toLowerCase();\n            if (!rsid.startsWith('rs')) {\n                rsid = `rs${rsid}`;\n            }\n        }\n\n        const log_pval = parsePvalToLog(fields[pvalue_col - 1], is_neg_log_pvalue);\n        ref = ref || null;\n        alt = alt || null;\n\n        if (has(allele_freq_col)) {\n            freq = fields[allele_freq_col - 1];\n        }\n        if (has(allele_count_col)) {\n            allele_count = fields[allele_count_col - 1];\n            n_samples = fields[n_samples_col - 1];\n        }\n\n        if (has(beta_col)) {\n            beta = fields[beta_col - 1];\n            beta = MISSING_VALUES.has(beta) ? null : (+beta);\n        }\n\n        if (has(stderr_beta_col)) {\n            stderr_beta = fields[stderr_beta_col - 1];\n            stderr_beta = MISSING_VALUES.has(stderr_beta) ? null : (+stderr_beta);\n        }\n\n        if (allele_freq_col || allele_count_col) {\n            alt_allele_freq = parseAlleleFrequency({\n                freq,\n                allele_count,\n                n_samples,\n                is_alt_effect,\n            });\n        }\n        const ref_alt = (ref && alt) ? `_${ref}/${alt}` : '';\n        return {\n            chromosome: chr,\n            position: +pos,\n            ref_allele: ref ? ref.toUpperCase() : null,\n            alt_allele: alt ? alt.toUpperCase() : null,\n            variant: `${chr}:${pos}${ref_alt}`,\n            rsid,\n            log_pvalue: log_pval,\n            beta,\n            stderr_beta,\n            alt_allele_freq,\n        };\n    };\n}\n\n\nexport { makeGWASParser };\n","/**\n * Parsers for custom user-specified LD\n */\n\nimport {normalizeChr} from './utils';\nimport {normalizeMarker} from '../../helpers/parse';\n\n/**\n * Parse the output of plink v1.9 R2 calculations relative to one (or a few) target SNPs.\n * See: https://www.cog-genomics.org/plink/1.9/ld and\n * reformatting commands at https://www.cog-genomics.org/plink/1.9/other\n * @function\n * @alias module:ext/lz-parsers~makePlinkLdParser\n * @param {object} options\n * @param {boolean} [options.normalize=true] Normalize fields to expected datatypes and format; if false, returns raw strings as given in the file\n * @return {function} A configured parser function that runs on one line of text from an input file\n */\nfunction makePlinkLdParser({normalize = true} = {}) {\n    return (line) => {\n        // Sample headers are below: SNP_A and SNP_B are based on ID column of the VCF\n        // CHR_A   BP_A    SNP_A   CHR_B   BP_B    SNP_B   R2\n        let [chromosome1, position1, variant1, chromosome2, position2, variant2, correlation] = line.trim().split('\\t');\n        if (normalize) {\n            chromosome1 = normalizeChr(chromosome1);\n            chromosome2 = normalizeChr(chromosome2);\n            variant1 = normalizeMarker(variant1);\n            variant2 = normalizeMarker(variant2);\n            position1 = +position1;\n            position2 = +position2;\n            correlation = +correlation;\n        }\n\n        return {chromosome1, position1, variant1, chromosome2, position2, variant2, correlation};\n    };\n}\n\nexport { makePlinkLdParser };\n"],"sourceRoot":""}